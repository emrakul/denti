{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting symspellpy\n",
      "  Downloading symspellpy-6.7.7-py3-none-any.whl (2.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting editdistpy>=0.1.3\n",
      "  Downloading editdistpy-0.1.3.tar.gz (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.2/57.2 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: editdistpy\n",
      "  Building wheel for editdistpy (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for editdistpy: filename=editdistpy-0.1.3-cp310-cp310-linux_x86_64.whl size=130264 sha256=3d4b39b643963edeaebe05cccdcc0856ee7bbe909640345ce543feea7cf0a06b\n",
      "  Stored in directory: /home/nikita/.cache/pip/wheels/88/6a/a6/a1283cc145323a1fb3d475bd158ee60b248ab1985230d266fc\n",
      "Successfully built editdistpy\n",
      "Installing collected packages: editdistpy, symspellpy\n",
      "Successfully installed editdistpy-0.1.3 symspellpy-6.7.7\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install symspellpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydub\n",
    "import librosa\n",
    "import nemo.collections.asr as nemo_asr\n",
    "import glob\n",
    "import nemo.collections.tts as nemo_tts\n",
    "import numpy as np\n",
    "import torch\n",
    "import pyctcdecode\n",
    "from word_beam_search import WordBeamSearch\n",
    "import itertools\n",
    "import symspellpy\n",
    "import matplotlib.pyplot as plt\n",
    "from forced_alignment import get_trellis, backtrack, plot_trellis_with_path, merge_repeats, plot_trellis_with_segments, merge_words\n",
    "import pickle\n",
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-12-16 20:16:57 cloud:56] Found existing object /home/nikita/.cache/torch/NeMo/NeMo_1.13.0/stt_en_quartznet15x5/16661021d16e679bdfd97a2a03944c49/stt_en_quartznet15x5.nemo.\n",
      "[NeMo I 2022-12-16 20:16:57 cloud:62] Re-using file from: /home/nikita/.cache/torch/NeMo/NeMo_1.13.0/stt_en_quartznet15x5/16661021d16e679bdfd97a2a03944c49/stt_en_quartznet15x5.nemo\n",
      "[NeMo I 2022-12-16 20:16:57 common:911] Instantiating model from pre-trained checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2022-12-16 20:16:58 modelPT:142] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: /data2/voices/train_1k.json\n",
      "    sample_rate: 16000\n",
      "    labels:\n",
      "    - ' '\n",
      "    - a\n",
      "    - b\n",
      "    - c\n",
      "    - d\n",
      "    - e\n",
      "    - f\n",
      "    - g\n",
      "    - h\n",
      "    - i\n",
      "    - j\n",
      "    - k\n",
      "    - l\n",
      "    - m\n",
      "    - 'n'\n",
      "    - o\n",
      "    - p\n",
      "    - q\n",
      "    - r\n",
      "    - s\n",
      "    - t\n",
      "    - u\n",
      "    - v\n",
      "    - w\n",
      "    - x\n",
      "    - 'y'\n",
      "    - z\n",
      "    - ''''\n",
      "    batch_size: 32\n",
      "    trim_silence: true\n",
      "    max_duration: 16.7\n",
      "    shuffle: true\n",
      "    is_tarred: false\n",
      "    tarred_audio_filepaths: /asr_set_1.2/train/train_{0..1023}.tar\n",
      "    num_workers: 20\n",
      "    \n",
      "[NeMo W 2022-12-16 20:16:58 modelPT:149] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath: /data2/voices/train_1k_samp.json\n",
      "    sample_rate: 16000\n",
      "    labels:\n",
      "    - ' '\n",
      "    - a\n",
      "    - b\n",
      "    - c\n",
      "    - d\n",
      "    - e\n",
      "    - f\n",
      "    - g\n",
      "    - h\n",
      "    - i\n",
      "    - j\n",
      "    - k\n",
      "    - l\n",
      "    - m\n",
      "    - 'n'\n",
      "    - o\n",
      "    - p\n",
      "    - q\n",
      "    - r\n",
      "    - s\n",
      "    - t\n",
      "    - u\n",
      "    - v\n",
      "    - w\n",
      "    - x\n",
      "    - 'y'\n",
      "    - z\n",
      "    - ''''\n",
      "    batch_size: 32\n",
      "    shuffle: false\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-12-16 20:16:58 features:225] PADDING: 16\n",
      "[NeMo I 2022-12-16 20:16:58 save_restore_connector:243] Model EncDecCTCModel was successfully restored from /home/nikita/.cache/torch/NeMo/NeMo_1.13.0/stt_en_quartznet15x5/16661021d16e679bdfd97a2a03944c49/stt_en_quartznet15x5.nemo.\n",
      "[NeMo I 2022-12-16 20:16:58 cloud:56] Found existing object /home/nikita/.cache/torch/NeMo/NeMo_1.13.0/commandrecognition_en_matchboxnet3x2x64_v2/8d5735c9c20648d313720dd95300978d/commandrecognition_en_matchboxnet3x2x64_v2.nemo.\n",
      "[NeMo I 2022-12-16 20:16:58 cloud:62] Re-using file from: /home/nikita/.cache/torch/NeMo/NeMo_1.13.0/commandrecognition_en_matchboxnet3x2x64_v2/8d5735c9c20648d313720dd95300978d/commandrecognition_en_matchboxnet3x2x64_v2.nemo\n",
      "[NeMo I 2022-12-16 20:16:58 common:911] Instantiating model from pre-trained checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2022-12-16 20:16:58 modelPT:142] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: null\n",
      "    sample_rate: 16000\n",
      "    labels:\n",
      "    - visual\n",
      "    - wow\n",
      "    - learn\n",
      "    - backward\n",
      "    - dog\n",
      "    - two\n",
      "    - left\n",
      "    - happy\n",
      "    - nine\n",
      "    - go\n",
      "    - up\n",
      "    - bed\n",
      "    - stop\n",
      "    - one\n",
      "    - zero\n",
      "    - tree\n",
      "    - seven\n",
      "    - 'on'\n",
      "    - four\n",
      "    - bird\n",
      "    - right\n",
      "    - eight\n",
      "    - 'no'\n",
      "    - six\n",
      "    - forward\n",
      "    - house\n",
      "    - marvin\n",
      "    - sheila\n",
      "    - five\n",
      "    - 'off'\n",
      "    - three\n",
      "    - down\n",
      "    - cat\n",
      "    - follow\n",
      "    - 'yes'\n",
      "    batch_size: 128\n",
      "    shuffle: true\n",
      "    is_tarred: false\n",
      "    tarred_audio_filepaths: null\n",
      "    tarred_shard_strategy: scatter\n",
      "    augmentor:\n",
      "      shift:\n",
      "        prob: 1.0\n",
      "        min_shift_ms: -5.0\n",
      "        max_shift_ms: 5.0\n",
      "      white_noise:\n",
      "        prob: 1.0\n",
      "        min_level: -90\n",
      "        max_level: -46\n",
      "    \n",
      "[NeMo W 2022-12-16 20:16:58 modelPT:149] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath: null\n",
      "    sample_rate: 16000\n",
      "    labels:\n",
      "    - visual\n",
      "    - wow\n",
      "    - learn\n",
      "    - backward\n",
      "    - dog\n",
      "    - two\n",
      "    - left\n",
      "    - happy\n",
      "    - nine\n",
      "    - go\n",
      "    - up\n",
      "    - bed\n",
      "    - stop\n",
      "    - one\n",
      "    - zero\n",
      "    - tree\n",
      "    - seven\n",
      "    - 'on'\n",
      "    - four\n",
      "    - bird\n",
      "    - right\n",
      "    - eight\n",
      "    - 'no'\n",
      "    - six\n",
      "    - forward\n",
      "    - house\n",
      "    - marvin\n",
      "    - sheila\n",
      "    - five\n",
      "    - 'off'\n",
      "    - three\n",
      "    - down\n",
      "    - cat\n",
      "    - follow\n",
      "    - 'yes'\n",
      "    batch_size: 128\n",
      "    shuffle: false\n",
      "    val_loss_idx: 0\n",
      "    \n",
      "[NeMo W 2022-12-16 20:16:58 modelPT:155] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
      "    Test config : \n",
      "    manifest_filepath:\n",
      "    - /home/smajumdar/PycharmProjects/nemo-eval/nemo_eval/speech_commands/v2_validation_manifest.json\n",
      "    - /home/smajumdar/PycharmProjects/nemo-eval/nemo_eval/speech_commands/v2_test_manifest.json\n",
      "    sample_rate: 16000\n",
      "    labels:\n",
      "    - visual\n",
      "    - wow\n",
      "    - learn\n",
      "    - backward\n",
      "    - dog\n",
      "    - two\n",
      "    - left\n",
      "    - happy\n",
      "    - nine\n",
      "    - go\n",
      "    - up\n",
      "    - bed\n",
      "    - stop\n",
      "    - one\n",
      "    - zero\n",
      "    - tree\n",
      "    - seven\n",
      "    - 'on'\n",
      "    - four\n",
      "    - bird\n",
      "    - right\n",
      "    - eight\n",
      "    - 'no'\n",
      "    - six\n",
      "    - forward\n",
      "    - house\n",
      "    - marvin\n",
      "    - sheila\n",
      "    - five\n",
      "    - 'off'\n",
      "    - three\n",
      "    - down\n",
      "    - cat\n",
      "    - follow\n",
      "    - 'yes'\n",
      "    batch_size: 128\n",
      "    shuffle: false\n",
      "    test_loss_idx: 0\n",
      "    num_workers: 12\n",
      "    pin_memory: true\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-12-16 20:16:58 save_restore_connector:243] Model EncDecClassificationModel was successfully restored from /home/nikita/.cache/torch/NeMo/NeMo_1.13.0/commandrecognition_en_matchboxnet3x2x64_v2/8d5735c9c20648d313720dd95300978d/commandrecognition_en_matchboxnet3x2x64_v2.nemo.\n"
     ]
    }
   ],
   "source": [
    "models = [\n",
    "    'stt_en_quartznet15x5',\n",
    "    #'QuartzNet15x5Base-En'\n",
    "    #'stt_en_jasper10x5dr'\n",
    "]\n",
    "#for model in models:\n",
    "asr = nemo_asr.models.EncDecCTCModel.from_pretrained(models[0], strict=False).eval().cpu()\n",
    "classifier = nemo_asr.models.EncDecClassificationModel.from_pretrained(\"commandrecognition_en_matchboxnet3x2x64_v2\").to('cpu').eval()\n",
    "config =asr.to_config_dict()\n",
    "labels = config['decoder']['vocabulary'] + ['']\n",
    "svm = pickle.load(open(\"svm.pkl\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Only 36 unigrams passed as vocabulary. Is this small or artificial data?\n",
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading /home/nikita/Documents/denti/text.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag = set()\n",
    "with open(\"train_text.txt\") as f:\n",
    "    t=f.readlines()\n",
    "    for line in t:\n",
    "        for word in line[:-1].split():\n",
    "            bag.add(word)\n",
    "bag.add('all')\n",
    "bag.add('on')\n",
    "bag.add('lingual')\n",
    "\n",
    "\n",
    "decoder = pyctcdecode.build_ctcdecoder(labels, \"text.arpa\", alpha=0.5, beta=1.5, lm_score_boundary=True, unigrams=list(bag))\n",
    "sm = symspellpy.SymSpell(max_dictionary_edit_distance=2)\n",
    "sm.create_dictionary(corpus=\"train_text.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocation|eighteen|grade|one\n",
      "furcation eighteen grade one\n",
      "furcation eighteen grade one\n",
      "[2]\n",
      "[2]\n",
      "[3]\n",
      "[3]\n",
      "jump|gingerval|mandin\n",
      "jump gingerval margin\n",
      "jump gingival margin\n",
      "[3]\n",
      "[5]\n",
      "[3]\n",
      "clack|light|on|all\n",
      "plaque light on all\n",
      "plaque light on all\n",
      "[5]\n",
      "[5]\n",
      "[3]\n",
      "[5]\n",
      "bleeding|thirteen|meseolingual\n",
      "bleeding thirteen mesialingual\n",
      "bleeding thirteen mesialingual\n",
      "[3]\n",
      "[3]\n",
      "[5]\n"
     ]
    }
   ],
   "source": [
    "for f in glob.glob(\"test/*.wav\"):\n",
    "    seg = pydub.AudioSegment.from_file(f)\n",
    "    samples = seg.get_array_of_samples()\n",
    "    samples = np.array(samples).astype(np.float32)\n",
    "    lengths = torch.IntTensor([len(samples)]).to('cpu')\n",
    "    samples = torch.FloatTensor(samples.reshape(1,-1)).to('cpu')\n",
    "    with torch.no_grad():\n",
    "        logs,_,tops = asr.forward(input_signal=samples, input_signal_length=lengths)\n",
    "    transcript = [labels[int(k)] for (k, g) in itertools.groupby(tops[0].numpy())]\n",
    "    baseline_text = ''.join(transcript)\n",
    "    print(baseline_text)\n",
    "    decoded_text = decoder.decode(logs[0].numpy(), hotwords=['mesial', 'light', 'margin', 'gingival', 'lingual'], hotword_weight=20)\n",
    "    print(decoded_text)\n",
    "    final_text = []\n",
    "    for word in decoded_text.split():\n",
    "        if word not in bag:\n",
    "            correct = sm.lookup_compound(word, 2)[0].term if len(sm.lookup(word.lower(), 2)) else word\n",
    "            final_text.append(correct)\n",
    "        else:\n",
    "            final_text.append(word)\n",
    "    final_text = \" \".join(final_text)\n",
    "\n",
    "    #final_text = [sm.lookup_compound(w, 2)[0].term if len(sm.lookup(w.lower(), 2)) else w for w in decoded_text.split()]\n",
    "    print(final_text)\n",
    "\n",
    "    labels = config['decoder']['vocabulary'] + ['']\n",
    "    labels[0] = '|'\n",
    "    transcript = [labels[int(k)] for (k, g) in itertools.groupby(tops[0].numpy())]\n",
    "    dictionary = {c: i for i, c in enumerate(labels)}\n",
    "    dictionary[''] = 0\n",
    "    dictionary['|'] = 28\n",
    "    tokens = [dictionary[c] for c in transcript]\n",
    "    trellis = get_trellis(logs[0], tokens)\n",
    "    path = backtrack(trellis, logs[0], tokens)\n",
    "    segments = merge_repeats(path, transcript)\n",
    "    word_segments = merge_words(segments)\n",
    "    y,_ = librosa.load(f, sr=16_000)\n",
    "    l = len(y)\n",
    "    for word in word_segments:\n",
    "        start = word.start/logs.shape[1]\n",
    "        end = word.end/logs.shape[1]\n",
    "        st = int(start*l)\n",
    "        end =int(end*l)\n",
    "        y0 = y[st:end]\n",
    "        input_signal = torch.FloatTensor([y0])\n",
    "        input_signal_length = torch.IntTensor([len(y0)])\n",
    "        res = classifier.forward(input_signal=input_signal, input_signal_length=input_signal_length)\n",
    "        X_vector = res.detach().numpy()[0]\n",
    "        class_ = svm.predict(X_vector.reshape(1,-1))\n",
    "        print(class_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7fd949f43caac0f2068892c27c1c66340460cb38bf9d2b065a617b577a92922b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
